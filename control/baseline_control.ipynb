{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99cf3a90",
   "metadata": {},
   "source": [
    "# Baseline Control Pipeline Notebook\n",
    "This notebook orchestrates the full baseline pipeline for the Siamese baseline:\n",
    "1. Split metadata into train/test sets\n",
    "2. Generate positive/negative pairs\n",
    "3. Train the baseline model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e5a35cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports succeeded!\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "# Compute directories\n",
    "cwd       = os.getcwd()\n",
    "repo_root = os.path.abspath(os.path.join(cwd, '..'))\n",
    "utils_dir = os.path.join(repo_root, 'utils')\n",
    "train_dir = os.path.join(repo_root, 'train')\n",
    "\n",
    "# Add to Python path\n",
    "sys.path.insert(0, utils_dir)\n",
    "sys.path.insert(0, train_dir)\n",
    "\n",
    "# Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pair_generator import PairGen          # in utils/\n",
    "from data_loader import ShapePairDataset    # in utils/\n",
    "import train_baseline                       # in train/\n",
    "\n",
    "print(\"Imports succeeded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e068a223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "metadata   = 'data/raw/metadata.jsonl'     # Path to the raw metadata JSONL file containing view records\n",
    "raw_dir    = 'data/raw'                    # Directory containing raw rendered images\n",
    "work_dir   = 'data/processed'              # Directory where processed metadata and pairs will be saved\n",
    "test_size  = 0.2                           # Fraction of data to reserve for the test set \n",
    "neg_ratio  = 1                             # Number of negative samples to generate per positive sample\n",
    "batch_size = 32                            # Batch size for training and evaluation\n",
    "epochs     = 10                            # Number of training epochs to run\n",
    "seed       = 42                            # Random seed for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d1df7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split metadata: 14400 train, 3600 test\n"
     ]
    }
   ],
   "source": [
    "# Split metadata into train/test \n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Compute paths\n",
    "repo_root = Path(os.getcwd()).parent\n",
    "meta_path = repo_root / metadata   \n",
    "\n",
    "# Load all view records\n",
    "with open(meta_path, 'r') as f:\n",
    "    records = [json.loads(line) for line in f]\n",
    "\n",
    "# Perform the split\n",
    "train_records, test_records = train_test_split(\n",
    "    records,\n",
    "    test_size=test_size,\n",
    "    random_state=seed,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Helper to write out JSONL files\n",
    "def write_jsonl(path, data):\n",
    "    path = Path(path)\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, 'w') as fw:\n",
    "        for rec in data:\n",
    "            fw.write(json.dumps(rec) + '\\n')\n",
    "\n",
    "# Write the splits\n",
    "train_meta_out = repo_root / work_dir / 'metadata_train.jsonl'\n",
    "test_meta_out  = repo_root / work_dir / 'metadata_test.jsonl'\n",
    "write_jsonl(train_meta_out, train_records)\n",
    "write_jsonl(test_meta_out,  test_records)\n",
    "\n",
    "print(f\"Split metadata: {len(train_records)} train, {len(test_records)} test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84834c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training pairs...\n",
      "Reading metadata from ..\\data\\processed\\metadata_train.jsonl...\n",
      "Found 14400 metadata entries.\n",
      "Generated 46096 positive pairs.\n",
      "Generated 46096 negative pairs.\n",
      "Saving 92192 pairs to ..\\data\\processed\\pairs_train.jsonl...\n",
      "Done.\n",
      "Generating test pairs...\n",
      "Reading metadata from ..\\data\\processed\\metadata_test.jsonl...\n",
      "Found 3600 metadata entries.\n",
      "Generated 2896 positive pairs.\n",
      "Generated 2896 negative pairs.\n",
      "Saving 5792 pairs to ..\\data\\processed\\pairs_test.jsonl...\n",
      "Done.\n",
      "Pairs written to:\n",
      "  data\\processed\\pairs_train.jsonl\n",
      "  data\\processed\\pairs_test.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Generate positive/negative pairs\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Compute path\n",
    "repo_root = Path(os.getcwd()).parent\n",
    "work_dir_path = repo_root / work_dir\n",
    "\n",
    "# Define output paths for the pairs files\n",
    "train_pairs_out = work_dir_path / 'pairs_train.jsonl'\n",
    "test_pairs_out  = work_dir_path / 'pairs_test.jsonl'\n",
    "\n",
    "# Generate training pairs\n",
    "print(\"Generating training pairs...\")\n",
    "PairGen(\n",
    "    input_file=str(train_meta_out),\n",
    "    output_file=str(train_pairs_out),\n",
    "    neg_samples_per_pos=neg_ratio\n",
    ").run()\n",
    "\n",
    "# Generate test pairs\n",
    "print(\"Generating test pairs...\")\n",
    "PairGen(\n",
    "    input_file=str(test_meta_out),\n",
    "    output_file=str(test_pairs_out),\n",
    "    neg_samples_per_pos=neg_ratio\n",
    ").run()\n",
    "\n",
    "# Print paths\n",
    "rel_train = train_pairs_out.relative_to(repo_root)\n",
    "rel_test  = test_pairs_out.relative_to(repo_root)\n",
    "print(\"Pairs written to:\")\n",
    "print(f\"  {rel_train}\")\n",
    "print(f\"  {rel_test}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
